{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"hS0f1i_javy9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}],"source":["from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","import numpy as np\n","\n","# Load MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n","X = mnist.data\n","y = mnist.target.astype(int)\n","\n","# Partition the data into multiple subsets\n","num_partitions = 5\n","X_partitions = np.array_split(X, num_partitions)\n","y_partitions = np.array_split(y, num_partitions)\n","\n","# Initialize list to store centroids\n","centroids = []\n","\n","# Loop through each partition\n","for X_partition, y_partition in zip(X_partitions, y_partitions):\n","    # Perform KNN on each partition to find the nearest neighbors\n","    n_neighbors = 5\n","    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    knn_model.fit(X_partition, y_partition)\n","    distances, indices = knn_model.kneighbors(X_partition)\n","\n","    # Calculate the centroid from each set of nearest neighbors\n","    centroid = np.mean(X_partition[indices], axis=1)\n","\n","    # Append the centroid to the list of centroids\n","    centroids.append(centroid)\n","\n","# Stack the centroids to form dataset R\n","R = np.vstack(centroids)\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(R, y, test_size=0.2, random_state=42)\n","\n","# Initialize Random Forest classifier\n","rf_model = RandomForestClassifier()\n","\n","# Define hyperparameters to tune for Random Forest\n","param_grid_rf = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Perform Grid Search with Cross-Validation for Random Forest\n","grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search_rf.fit(X_train, y_train)\n","\n","# Get the best Random Forest model\n","best_rf_model = grid_search_rf.best_estimator_\n","\n","# Evaluate the best Random Forest model\n","accuracy_rf = best_rf_model.score(X_test, y_test)\n","print(\"Random Forest Model Accuracy:\", accuracy_rf)\n","\n","# Initialize Gradient Boosting classifier\n","gb_model = GradientBoostingClassifier()\n","\n","# Define hyperparameters to tune for Gradient Boosting\n","param_grid_gb = {\n","    'n_estimators': [100, 200, 300],\n","    'learning_rate': [0.05, 0.1, 0.2],\n","    'max_depth': [3, 4, 5]\n","}\n","\n","# Perform Grid Search with Cross-Validation for Gradient Boosting\n","grid_search_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search_gb.fit(X_train, y_train)\n","\n","# Get the best Gradient Boosting model\n","best_gb_model = grid_search_gb.best_estimator_\n","\n","# Evaluate the best Gradient Boosting model\n","accuracy_gb = best_gb_model.score(X_test, y_test)\n","print(\"Gradient Boosting Model Accuracy:\", accuracy_gb)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPQiL81FvK3O+2UU5PUG7zK","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}