{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPc+uxWRrX+VHFWeFnVbfI0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5D1FUCuWp93","executionInfo":{"status":"ok","timestamp":1713347114830,"user_tz":-360,"elapsed":1518055,"user":{"displayName":"Emon Karmaker","userId":"09813692096123274517"}},"outputId":"555a2c5c-2db7-4c01-aae5-495e7badefc6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Cross-Validation Accuracy: 0.9639464285714284\n","Cross-Validation Precision: 0.9629035894080016\n","Cross-Validation Recall: 0.96325\n","Test Accuracy: 0.9625\n","Test Precision: 0.9625085879225491\n","Test Recall: 0.9625\n"]}],"source":["import numpy as np\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","\n","# Fetch the MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1)\n","\n","# Split the dataset into features (X) and target labels (y)\n","X, y = mnist.data, mnist.target\n","\n","# Convert target labels to integers\n","y = y.astype(np.uint8)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define the model\n","rf_model = RandomForestClassifier()\n","\n","# Define hyperparameters to tune\n","param_dist = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [10, 20, 30, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Perform Randomized Search with Cross-Validation\n","random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n","random_search.fit(X_train, y_train)\n","\n","# Get the best model\n","best_rf_model = random_search.best_estimator_\n","\n","# Evaluate the best model using cross-validation\n","cv_accuracy = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='accuracy')\n","cv_precision = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='precision_weighted')\n","cv_recall = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='recall_weighted')\n","\n","# Fit the best model on the full training set\n","best_rf_model.fit(X_train, y_train)\n","\n","# Evaluate the best model on the test set\n","y_pred = best_rf_model.predict(X_test)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","print(\"Cross-Validation Accuracy:\", np.mean(cv_accuracy))\n","print(\"Cross-Validation Precision:\", np.mean(cv_precision))\n","print(\"Cross-Validation Recall:\", np.mean(cv_recall))\n","print(\"Test Accuracy:\", accuracy)\n","print(\"Test Precision:\", precision)\n","print(\"Test Recall:\", recall)\n"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_selection import SelectFromModel\n","\n","# Fetch the MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1)\n","\n","# Split the dataset into features (X) and target labels (y)\n","X, y = mnist.data, mnist.target\n","\n","# Convert target labels to integers\n","y = y.astype(np.uint8)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Feature Scaling\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Feature Selection\n","rf_model = RandomForestClassifier()\n","selector = SelectFromModel(estimator=rf_model).fit(X_train_scaled, y_train)\n","X_train_selected = selector.transform(X_train_scaled)\n","X_test_selected = selector.transform(X_test_scaled)\n","\n","# Define the model\n","rf_model = RandomForestClassifier()\n","\n","# Define hyperparameters to tune\n","param_dist = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [10, 20, 30, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Perform Randomized Search with Cross-Validation\n","random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n","random_search.fit(X_train_selected, y_train)\n","\n","# Get the best model\n","best_rf_model = random_search.best_estimator_\n","\n","# Evaluate the best model using cross-validation\n","cv_accuracy = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='accuracy')\n","cv_precision = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='precision_weighted')\n","cv_recall = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='recall_weighted')\n","\n","# Fit the best model on the full training set\n","best_rf_model.fit(X_train_selected, y_train)\n","\n","# Evaluate the best model on the test set\n","y_pred = best_rf_model.predict(X_test_selected)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","print(\"Cross-Validation Accuracy:\", np.mean(cv_accuracy))\n","print(\"Cross-Validation Precision:\", np.mean(cv_precision))\n","print(\"Cross-Validation Recall:\", np.mean(cv_recall))\n","print(\"Test Accuracy:\", accuracy)\n","print(\"Test Precision:\", precision)\n","print(\"Test Recall:\", recall)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJ8xkcNic14S","executionInfo":{"status":"ok","timestamp":1713349450331,"user_tz":-360,"elapsed":2255180,"user":{"displayName":"Emon Karmaker","userId":"09813692096123274517"}},"outputId":"95a139a1-f0fc-4cf6-938f-1860b2b448a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Cross-Validation Accuracy: 0.9646607142857142\n","Cross-Validation Precision: 0.9649946296758032\n","Cross-Validation Recall: 0.9646607142857142\n","Test Accuracy: 0.9659285714285715\n","Test Precision: 0.9659787118085993\n","Test Recall: 0.9659285714285715\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_selection import SelectFromModel\n","from PIL import Image\n","\n","# Function to load data from the folder\n","def load_data_from_folder(folder):\n","    X, y = [], []\n","    for label in os.listdir(folder):\n","        label_folder = os.path.join(folder, label)\n","        for image_file in os.listdir(label_folder):\n","            try:\n","                # Open the image file\n","                image_path = os.path.join(label_folder, image_file)\n","                with Image.open(image_path) as img:\n","                    # Convert the image to grayscale and resize it to 28x28\n","                    img = img.convert('L').resize((28, 28))\n","                    # Convert image to numpy array and flatten it\n","                    img_array = np.array(img).flatten()\n","                    X.append(img_array)\n","                    y.append(label)\n","            except Exception as e:\n","                print(f\"Error processing image {image_path}: {e}\")\n","    return np.array(X), np.array(y)\n","\n","# Extract the dataset\n","!tar -xzf notMNIST_small.tar.gz\n","\n","# Define the path to the extracted dataset folder\n","data_folder = 'notMNIST_small'\n","\n","# Load the dataset\n","X, y = load_data_from_folder(data_folder)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Feature Scaling\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Feature Selection\n","rf_model = RandomForestClassifier()\n","selector = SelectFromModel(estimator=rf_model).fit(X_train_scaled, y_train)\n","X_train_selected = selector.transform(X_train_scaled)\n","X_test_selected = selector.transform(X_test_scaled)\n","\n","# Define the model\n","rf_model = RandomForestClassifier()\n","\n","# Define hyperparameters to tune\n","param_dist = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [20, 30, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['auto', 'sqrt', 'log2']\n","}\n","\n","# Perform Randomized Search with Cross-Validation\n","random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n","random_search.fit(X_train_selected, y_train)\n","\n","# Get the best model\n","best_rf_model = random_search.best_estimator_\n","\n","# Evaluate the best model using cross-validation\n","cv_accuracy = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='accuracy')\n","cv_precision = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='precision_weighted')\n","cv_recall = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='recall_weighted')\n","\n","# Fit the best model on the full training set\n","best_rf_model.fit(X_train_selected, y_train)\n","\n","# Evaluate the best model on the test set\n","y_pred = best_rf_model.predict(X_test_selected)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","print(\"Cross-Validation Accuracy:\", np.mean(cv_accuracy))\n","print(\"Cross-Validation Precision:\", np.mean(cv_precision))\n","print(\"Cross-Validation Recall:\", np.mean(cv_recall))\n","print(\"Test Accuracy:\", accuracy)\n","print(\"Test Precision:\", precision)\n","print(\"Test Recall:\", recall)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HijdlmLIljKZ","executionInfo":{"status":"ok","timestamp":1713351255118,"user_tz":-360,"elapsed":989718,"user":{"displayName":"Emon Karmaker","userId":"09813692096123274517"}},"outputId":"211860de-b772-4619-80fe-a5ee86f61ccf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error processing image notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png: cannot identify image file 'notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png'\n","Error processing image notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png: cannot identify image file 'notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png'\n","Cross-Validation Accuracy: 0.9108083566068057\n","Cross-Validation Precision: 0.9116420011180416\n","Cross-Validation Recall: 0.9111422910012459\n","Test Accuracy: 0.9073431241655541\n","Test Precision: 0.9077473356959932\n","Test Recall: 0.9073431241655541\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_selection import SelectFromModel\n","import tensorflow_datasets as tfds\n","\n","# Load the Kuzushiji-MNIST dataset from TensorFlow Datasets\n","ds_train, ds_test = tfds.load('kmnist', split=['train', 'test'], as_supervised=True)\n","\n","# Convert TensorFlow Datasets to NumPy arrays\n","X_train, y_train = [], []\n","X_test, y_test = [], []\n","\n","for image, label in tfds.as_numpy(ds_train):\n","    X_train.append(image.flatten())\n","    y_train.append(label)\n","\n","for image, label in tfds.as_numpy(ds_test):\n","    X_test.append(image.flatten())\n","    y_test.append(label)\n","\n","# Convert lists to NumPy arrays\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","X_test = np.array(X_test)\n","y_test = np.array(y_test)\n","\n","# Preprocess the dataset (scale features)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Feature Selection\n","rf_model = RandomForestClassifier()\n","selector = SelectFromModel(estimator=rf_model).fit(X_train_scaled, y_train)\n","X_train_selected = selector.transform(X_train_scaled)\n","X_test_selected = selector.transform(X_test_scaled)\n","\n","# Define the model\n","rf_model = RandomForestClassifier()\n","\n","# Define hyperparameters to tune\n","param_dist = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [20, 30, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['auto', 'sqrt', 'log2']\n","}\n","\n","# Perform Randomized Search with Cross-Validation\n","random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=-1)\n","random_search.fit(X_train_selected, y_train)\n","\n","# Get the best model\n","best_rf_model = random_search.best_estimator_\n","\n","# Evaluate the best model using cross-validation\n","cv_accuracy = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='accuracy')\n","cv_precision = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='precision_weighted')\n","cv_recall = cross_val_score(best_rf_model, X_train_selected, y_train, cv=5, scoring='recall_weighted')\n","\n","# Fit the best model on the full training set\n","best_rf_model.fit(X_train_selected, y_train)\n","\n","# Evaluate the best model on the test set\n","y_pred = best_rf_model.predict(X_test_selected)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(\"Cross-Validation Accuracy:\", np.mean(cv_accuracy))\n","print(\"Cross-Validation Precision:\", np.mean(cv_precision))\n","print(\"Cross-Validation Recall:\", np.mean(cv_recall))\n","print(\"Test Accuracy:\", accuracy)\n","print(\"Test Precision:\", precision)\n","print(\"Test Recall:\", recall)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q26u59UgzYh0","executionInfo":{"status":"ok","timestamp":1713361731811,"user_tz":-360,"elapsed":5030898,"user":{"displayName":"Emon Karmaker","userId":"09813692096123274517"}},"outputId":"94f61926-d7df-4339-9a18-394ae2bbe19f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n","/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Cross-Validation Accuracy: 0.9281333333333333\n","Cross-Validation Precision: 0.9292196182990559\n","Cross-Validation Recall: 0.9279833333333333\n","Test Accuracy: 0.8352\n","Test Precision: 0.838944642289922\n","Test Recall: 0.8352\n"]}]}]}