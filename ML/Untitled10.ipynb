{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQqfwbtszRjf9CbYuFKZcH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mff3gqpY6xnt","executionInfo":{"status":"ok","timestamp":1709548768195,"user_tz":-360,"elapsed":2042899,"user":{"displayName":"Emon Karmaker","userId":"09813692096123274517"}},"outputId":"c906e161-98a2-4004-f967-96f2eb7c49a8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model Accuracy: 0.9099285714285714\n"]}],"source":["from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","import numpy as np\n","\n","# Load MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n","X = mnist.data\n","y = mnist.target.astype(int)\n","\n","# Partition the data into multiple subsets\n","num_partitions = 5\n","X_partitions = np.array_split(X, num_partitions)\n","y_partitions = np.array_split(y, num_partitions)\n","\n","# Initialize list to store centroids\n","centroids = []\n","\n","# Loop through each partition\n","for X_partition, y_partition in zip(X_partitions, y_partitions):\n","    # Perform KNN on each partition to find the nearest neighbors\n","    n_neighbors = 5\n","    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    knn_model.fit(X_partition, y_partition)\n","    distances, indices = knn_model.kneighbors(X_partition)\n","\n","    # Calculate the centroid from each set of nearest neighbors\n","    centroid = np.mean(X_partition[indices], axis=1)\n","\n","    # Append the centroid to the list of centroids\n","    centroids.append(centroid)\n","\n","# Stack the centroids to form dataset R\n","R = np.vstack(centroids)\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(R, y, test_size=0.2, random_state=42)\n","\n","# Initialize Decision Tree classifier\n","dt_model = DecisionTreeClassifier()\n","\n","# Define hyperparameters to tune\n","param_grid = {\n","    'max_depth': [None, 100, 200, 300],\n","    'min_samples_split': [20, 50, 100],\n","    'min_samples_leaf': [10, 20, 40]\n","}\n","\n","# Perform Grid Search with Cross-Validation\n","grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best model\n","best_dt_model = grid_search.best_estimator_\n","\n","# Evaluate the best model\n","accuracy = best_dt_model.score(X_test, y_test)\n","print(\"Model Accuracy:\", accuracy)\n"]},{"cell_type":"code","source":["from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","import numpy as np\n","\n","# Load MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n","X = mnist.data\n","y = mnist.target.astype(int)\n","\n","# Partition the data into multiple subsets\n","num_partitions = 5\n","X_partitions = np.array_split(X, num_partitions)\n","y_partitions = np.array_split(y, num_partitions)\n","\n","# Initialize list to store centroids\n","centroids = []\n","\n","# Loop through each partition\n","for X_partition, y_partition in zip(X_partitions, y_partitions):\n","    # Perform KNN on each partition to find the nearest neighbors\n","    n_neighbors = 5\n","    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n","    knn_model.fit(X_partition, y_partition)\n","    distances, indices = knn_model.kneighbors(X_partition)\n","\n","    # Calculate the centroid from each set of nearest neighbors\n","    centroid = np.mean(X_partition[indices], axis=1)\n","\n","    # Append the centroid to the list of centroids\n","    centroids.append(centroid)\n","\n","# Stack the centroids to form dataset R\n","R = np.vstack(centroids)\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(R, y, test_size=0.2, random_state=42)\n","\n","# Initialize Decision Tree classifier\n","dt_model = DecisionTreeClassifier()\n","\n","param_grid = {\n","    'max_depth': [None, 10, 20, 30, 40, 50],\n","    'min_samples_split': [5, 8, 15],\n","    'min_samples_leaf': [10, 4, 8]\n","}\n","\n","# Perform Grid Search with Cross-Validation\n","grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best model\n","best_dt_model = grid_search.best_estimator_\n","\n","# Evaluate the best model\n","accuracy = best_dt_model.score(X_test, y_test)\n","print(\"Model Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJY1B3Xx7OLu","executionInfo":{"status":"ok","timestamp":1709552011753,"user_tz":-360,"elapsed":3243565,"user":{"displayName":"Emon Karmaker","userId":"09813692096123274517"}},"outputId":"b0d82b3b-7cfd-423a-9ab7-85202b32b10e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model Accuracy: 0.9140714285714285\n"]}]}]}