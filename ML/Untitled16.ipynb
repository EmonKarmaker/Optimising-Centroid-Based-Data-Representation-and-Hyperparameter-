{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJU8H7inXwJva0GDk4zlvy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tJUop4vuc-e7"},"outputs":[],"source":["import numpy as np\n","from torchvision import datasets, transforms\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from joblib import parallel_backend\n","\n","# Define transformation to convert images to PyTorch tensors and normalize them\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","# Download QMNIST dataset\n","train_dataset = datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.QMNIST(root='./data', train=False, download=True, transform=transform)\n","\n","# Extract features and labels from the dataset\n","X_train = train_dataset.data.numpy()\n","y_train = train_dataset.targets.numpy()\n","X_test = test_dataset.data.numpy()\n","y_test = test_dataset.targets.numpy()\n","\n","# Partition the data into multiple subsets\n","num_partitions = 5\n","X_partitions = np.array_split(X_train, num_partitions)\n","y_partitions = np.array_split(y_train, num_partitions)\n","\n","# Initialize list to store centroids\n","centroids = []\n","\n","# Loop through each partition\n","for X_partition, y_partition in zip(X_partitions, y_partitions):\n","    # Train KNN on each partition to find the nearest neighbors and compute centroid\n","    knn_model = KNeighborsClassifier(n_neighbors=5)\n","    knn_model.fit(X_partition.reshape(len(X_partition), -1), y_partition)\n","    distances, indices = knn_model.kneighbors(X_partition.reshape(len(X_partition), -1))\n","    centroid = np.mean(X_partition[indices], axis=1)\n","    centroids.append(centroid)\n","\n","# Stack the centroids to form dataset R\n","R = np.vstack(centroids)\n","\n","# Split the data into train and test sets for dataset R\n","X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(R, y_train, test_size=0.2, random_state=42)\n","\n","# Initialize Decision Tree classifier for dataset R\n","dt_model_r = DecisionTreeClassifier()\n","\n","# Define hyperparameters to tune for Decision Tree classifier\n","param_grid_r = {\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Perform Grid Search with Cross-Validation for Decision Tree classifier for dataset R\n","with parallel_backend('threading'):\n","    grid_search_r = GridSearchCV(estimator=dt_model_r, param_grid=param_grid_r, cv=5, scoring='accuracy', n_jobs=-1)\n","    grid_search_r.fit(X_train_r.reshape(len(X_train_r), -1), y_train_r)\n","\n","# Get the best model for Decision Tree classifier for dataset R\n","best_dt_model_r = grid_search_r.best_estimator_\n","\n","# Evaluate the best model on the test set for Decision Tree classifier for dataset R\n","accuracy_r = best_dt_model_r.score(X_test_r.reshape(len(X_test_r), -1), y_test_r)\n","print(\"Model Accuracy (Decision Tree with centroids):\", accuracy_r)\n"]}]}